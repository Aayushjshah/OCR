{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cgrd3FlJDn2u"
   },
   "source": [
    "# <font color=\"blue\">Introduction to Tesseract</font>\n",
    "Tesseract is an open source text recognition (OCR) Engine - It is used to extract text from images. It is available under the Apache 2.0 license. It is also one of the best free softwares for performing OCR.\n",
    "\n",
    "Tesseract was originally developed at HP between 1985 and 1998. In 2005 Tesseract was open sourced by HP. Since 2006 it is developed by Google.\n",
    "\n",
    "The latest (LSTM based) stable version is v4.x which supports many additional languages ( around 116 languages ). \n",
    "\n",
    "We will use pytesseract - a python wrapper for Tesseract in this course.\n",
    "\n",
    "In this notebook, we will see the supported functions and how to extract text from images. We will also see how to use it for other langauges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ONKd4B6G-f8i"
   },
   "source": [
    "# <font color=\"blue\">Install Tesseract library</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                 Version\n",
      "----------------------- -----------\n",
      "about-time              4.2.1\n",
      "absl-py                 1.4.0\n",
      "aiohttp                 3.9.3\n",
      "aiosignal               1.2.0\n",
      "alive-progress          3.1.1\n",
      "anyio                   3.5.0\n",
      "appdirs                 1.4.4\n",
      "argon2-cffi             21.3.0\n",
      "argon2-cffi-bindings    21.2.0\n",
      "asttokens               2.0.5\n",
      "astunparse              1.6.3\n",
      "async-timeout           4.0.3\n",
      "attrs                   22.1.0\n",
      "backcall                0.2.0\n",
      "beautifulsoup4          4.11.1\n",
      "bleach                  4.1.0\n",
      "blinker                 1.6.2\n",
      "Bottleneck              1.3.5\n",
      "brotlipy                0.7.0\n",
      "cachetools              4.2.2\n",
      "certifi                 2024.2.2\n",
      "cffi                    1.15.1\n",
      "charset-normalizer      2.0.4\n",
      "click                   8.1.7\n",
      "cmake                   3.28.1\n",
      "colorama                0.4.6\n",
      "comm                    0.1.2\n",
      "contourpy               1.0.5\n",
      "cryptography            39.0.1\n",
      "cycler                  0.11.0\n",
      "debugpy                 1.5.1\n",
      "decorator               5.1.1\n",
      "defusedxml              0.7.1\n",
      "dlib                    19.24.2\n",
      "entrypoints             0.4\n",
      "et-xmlfile              1.1.0\n",
      "executing               0.8.3\n",
      "fastjsonschema          2.16.2\n",
      "filelock                3.9.0\n",
      "flatbuffers             2.0\n",
      "flit_core               3.8.0\n",
      "fonttools               4.25.0\n",
      "frozenlist              1.4.0\n",
      "fsspec                  2023.9.2\n",
      "gast                    0.4.0\n",
      "google-auth             2.22.0\n",
      "google-auth-oauthlib    0.4.4\n",
      "google-pasta            0.2.0\n",
      "grapheme                0.6.0\n",
      "grpcio                  1.42.0\n",
      "h5py                    3.9.0\n",
      "huggingface-hub         0.17.3\n",
      "idna                    3.4\n",
      "install                 1.3.5\n",
      "ipykernel               6.19.2\n",
      "ipython                 8.10.0\n",
      "ipython-genutils        0.2.0\n",
      "ipywidgets              8.0.6\n",
      "jedi                    0.18.1\n",
      "Jinja2                  3.1.2\n",
      "joblib                  1.2.0\n",
      "jsonschema              4.17.3\n",
      "jupyter_client          7.4.9\n",
      "jupyter_core            5.2.0\n",
      "jupyter-server          1.23.4\n",
      "jupyterlab-pygments     0.1.2\n",
      "jupyterlab-widgets      3.0.7\n",
      "keras                   2.10.0\n",
      "Keras-Preprocessing     1.1.2\n",
      "kiwisolver              1.4.4\n",
      "lxml                    4.9.1\n",
      "Markdown                3.4.1\n",
      "MarkupSafe              2.1.1\n",
      "matplotlib              3.7.1\n",
      "matplotlib-inline       0.1.6\n",
      "mistune                 0.8.4\n",
      "mkl-fft                 1.3.1\n",
      "mkl-random              1.2.2\n",
      "mkl-service             2.4.0\n",
      "mpmath                  1.2.1\n",
      "multidict               6.0.4\n",
      "munkres                 1.1.4\n",
      "nbclassic               0.5.2\n",
      "nbclient                0.5.13\n",
      "nbconvert               6.5.4\n",
      "nbformat                5.7.0\n",
      "nest-asyncio            1.5.6\n",
      "networkx                2.8.4\n",
      "notebook                6.5.4\n",
      "notebook_shim           0.2.2\n",
      "numexpr                 2.8.4\n",
      "numpy                   1.23.5\n",
      "oauthlib                3.2.2\n",
      "opencv-contrib-python   4.9.0.80\n",
      "opencv-python           4.9.0.80\n",
      "openpyxl                3.0.10\n",
      "opt-einsum              3.3.0\n",
      "packaging               23.0\n",
      "pandas                  1.5.3\n",
      "pandocfilters           1.5.0\n",
      "parso                   0.8.3\n",
      "patsy                   0.5.6\n",
      "pickleshare             0.7.5\n",
      "Pillow                  9.4.0\n",
      "pip                     23.0.1\n",
      "platformdirs            2.5.2\n",
      "ply                     3.11\n",
      "pooch                   1.6.0\n",
      "prometheus-client       0.14.1\n",
      "prompt-toolkit          3.0.36\n",
      "protobuf                3.20.3\n",
      "psutil                  5.9.0\n",
      "pure-eval               0.2.2\n",
      "pyasn1                  0.4.8\n",
      "pyasn1-modules          0.2.8\n",
      "pycparser               2.21\n",
      "Pygments                2.11.2\n",
      "PyJWT                   2.4.0\n",
      "pyOpenSSL               23.0.0\n",
      "pyparsing               3.0.9\n",
      "PyQt5                   5.15.7\n",
      "PyQt5-sip               12.11.0\n",
      "pyrsistent              0.18.0\n",
      "PySocks                 1.7.1\n",
      "python-dateutil         2.8.2\n",
      "pytz                    2022.7\n",
      "pywin32                 305.1\n",
      "pywinpty                2.0.10\n",
      "PyYAML                  6.0.1\n",
      "pyzmq                   23.2.0\n",
      "regex                   2023.10.3\n",
      "requests                2.28.1\n",
      "requests-oauthlib       1.3.0\n",
      "rsa                     4.7.2\n",
      "safetensors             0.4.0\n",
      "scikit-learn            1.2.1\n",
      "scipy                   1.10.0\n",
      "seaborn                 0.13.2\n",
      "Send2Trash              1.8.0\n",
      "setuptools              65.6.3\n",
      "sip                     6.6.2\n",
      "six                     1.16.0\n",
      "sniffio                 1.2.0\n",
      "soupsieve               2.3.2.post1\n",
      "stack-data              0.2.0\n",
      "statsmodels             0.14.1\n",
      "sympy                   1.11.1\n",
      "tensorboard             2.10.0\n",
      "tensorboard-data-server 0.6.1\n",
      "tensorboard-plugin-wit  1.8.1\n",
      "tensorflow              2.10.0\n",
      "tensorflow-estimator    2.10.0\n",
      "termcolor               2.1.0\n",
      "terminado               0.17.1\n",
      "threadpoolctl           3.1.0\n",
      "tinycss2                1.2.1\n",
      "tokenizers              0.14.1\n",
      "toml                    0.10.2\n",
      "torch                   2.0.0\n",
      "torch-geometric         2.3.0\n",
      "torchaudio              2.0.0\n",
      "torchvision             0.15.0\n",
      "tornado                 6.2\n",
      "tqdm                    4.65.0\n",
      "traitlets               5.7.1\n",
      "transformers            4.34.0\n",
      "typing_extensions       4.4.0\n",
      "urllib3                 1.26.14\n",
      "wcwidth                 0.2.5\n",
      "webencodings            0.5.1\n",
      "websocket-client        0.58.0\n",
      "Werkzeug                2.3.8\n",
      "wheel                   0.38.4\n",
      "widgetsnbextension      4.0.7\n",
      "win-inet-pton           1.1.0\n",
      "wincertstore            0.2\n",
      "wrapt                   1.14.1\n",
      "yarl                    1.9.3\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Ip5LAcpMVpoz",
    "outputId": "c6d3e17a-92c5-4c58-a170-03b0edd6ac73"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "!choco install libtesseract-dev tesseract-ocr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LTLWqG-4-_BH"
   },
   "source": [
    "# <font color=\"blue\">Install Python wrapper for Tesseract </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k7F0IyJ8VfnG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytesseract\n",
      "  Using cached pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\acer\\anaconda3\\envs\\vision\\lib\\site-packages (from pytesseract) (23.0)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\acer\\anaconda3\\envs\\vision\\lib\\site-packages (from pytesseract) (9.4.0)\n",
      "Installing collected packages: pytesseract\n",
      "Successfully installed pytesseract-0.3.10\n"
     ]
    }
   ],
   "source": [
    "!pip install pytesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EhDZ1eVK_Evf"
   },
   "source": [
    "# <font color=\"blue\">Import Libraries </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VR5F102-Vt_v"
   },
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3b4M_3GiBimN"
   },
   "source": [
    "# <font color=\"blue\">Test Image 1 </font>\n",
    "We will download a screenshot taken from the Keras Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wZWkPYFn-a5z"
   },
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/v3z5l2mq8swea1e/keras-snapshot.jpg?dl=1 -O text1.jpg --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WOY-44PLED7k"
   },
   "source": [
    "### <font color=\"green\">Downloaded Image</font>\n",
    "![](https://www.dropbox.com/s/v3z5l2mq8swea1e/keras-snapshot.jpg?dl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rri99QrnDYb5"
   },
   "source": [
    "# <font color=\"blue\">Perform OCR</font>\n",
    "Tesseract provides a very easy to use interface (with a lot of flexibility and parameters) to perform OCR on images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7VqqCzFj_KfV"
   },
   "source": [
    "### <font color=\"green\">Output </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "juIRqDHY-bCP",
    "outputId": "abf8c3be-e45c-4c17-ca89-af90fd762a55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras is a high-level neural networks API, written in Python and capable of running on top of\n",
      "TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation.\n",
      "Being able to go from idea to result with the least possible delay is key to doing good research.\n"
     ]
    }
   ],
   "source": [
    "text1 = pytesseract.image_to_string('text1.jpg')\n",
    "print(text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bCHvJ2m2YBXC"
   },
   "source": [
    "# <font color=\"blue\">Test Image 2 </font>\n",
    "We will use a screenshot of a full page from Chapter 9 of deep learning book by Ian Goodfellow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "twGSNoAZ-ba2"
   },
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/ai7dsbpsyjb2inx/cnn-snapshot.jpg?dl=1 -O text2.jpg --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gX-UF6MaEo_f"
   },
   "source": [
    "### Downloaded Image\n",
    "![](https://www.dropbox.com/s/ai7dsbpsyjb2inx/cnn-snapshot.jpg?dl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jjD_6FvH_C27"
   },
   "source": [
    "### <font color=\"green\">Output </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "e6nqEiwF-biQ",
    "outputId": "54edd0e0-bb34-4c6f-8850-86ca088c6836"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter 9\n",
      "\n",
      "Convolutional Networks\n",
      "\n",
      "Convolutional networks (LeCun, 1989), also known as convolutional neural\n",
      "networks, or CNNs, are a specialized kind of neural network for processing data\n",
      "that has a known grid-like topology. Examples include time-series data, which can\n",
      "be thought of as a 1-D grid taking samples at regular time intervals, and image data,\n",
      "which can be thought of as a 2-D grid of pixels. Convolutional networks have been\n",
      "tremendously successful in practical applications. The name “convolutional neural\n",
      "network” indicates that the network employs a mathematical operation called\n",
      "convolution. Convolution is a specialized kind of linear operation. Convolutional\n",
      "networks are simply neural networks that use convolution in place of general matrix\n",
      "multiplication in at least one of their layers.\n",
      "\n",
      "In this chapter, we first describe what convolution is. Next, we explain the\n",
      "motivation behind using convolution in a neural network. We then describe an\n",
      "operation called pooling, which almost all convolutional networks employ. Usually,\n",
      "the operation used in a convolutional neural network does not correspond precisely\n",
      "to the definition of convolution as used in other fields, such as engineering or\n",
      "pure mathematics. We describe several variants on the convolution function that\n",
      "are widely used in practice for neural networks. We also show how convolution\n",
      "may be applied to many kinds of data, with different numbers of dimensions. We\n",
      "then discuss means of making convolution more efficient. Convolutional networks\n",
      "stand out as an example of neuroscientific principles influencing deep learning.\n",
      "We discuss these neuroscientific principles, then conclude with comments about\n",
      "the role convolutional networks have played in the history of deep learning. One\n",
      "topic this chapter does not address is how to choose the architecture of your\n",
      "convolutional network. The goal of this chapter is to describe the kinds of tools\n",
      "that convolutional networks provide, while chapter 11 describes general guidelines\n"
     ]
    }
   ],
   "source": [
    "text2 = pytesseract.image_to_string('text2.jpg')\n",
    "print(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qw1LLu0wGhpM"
   },
   "source": [
    "### <font color=\"green\">Observation </font>\n",
    "Wow! It does a really good job even with a large text body.\n",
    "\n",
    "It identifies special characters like  \"(\" , \".\" , \",\" , \"-\" , etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hkf6uzz3YOHD"
   },
   "source": [
    "# <font color=\"blue\">Test Image 3</font>\n",
    "Till now we have seen \"nice\" images with uniform white backgrounds and black text. Let us make life a little harder for Tesseract with some different color background and non-uniform text. \n",
    "\n",
    "We will use a scanned image of the back of Computer Vision book by Forsyth and Ponce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1miIN4EsYYRY"
   },
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/zrr4tvozzjbfrzv/forsyth_scan.jpg?dl=1 -O text3.jpg --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZQFZ90CCYcD0"
   },
   "source": [
    "### <font color=\"green\">Downloaded Image</font>\n",
    "<img src=\"https://www.dropbox.com/s/zrr4tvozzjbfrzv/forsyth_scan.jpg?dl=1\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ne4E4fIu_WjI"
   },
   "source": [
    "### <font color=\"green\">Output </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "colab_type": "code",
    "id": "KCkqoAqPYYPP",
    "outputId": "e98183bf-c5e4-4d21-c52f-b39662d81658"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computer Vision\n",
      "\n",
      "A MODERN APPROACH\n",
      "\n",
      "DAVID A. FORSYTH\n",
      "\n",
      "University of California at Berkeley\n",
      "\n",
      "JEAN PONCE\n",
      "\n",
      "University of Illinois at Urbana-Champaign\n",
      "\n",
      " \n",
      "\n",
      "Whether in the entertainment industry (building three-dimensiona! computer models), medical imaging,\n",
      "interpreting satellite images (both for military and civilian purposes), the applications of computer\n",
      "vision is varied and wide ranging. And this compact yet comprehensive text provides a survey of the\n",
      "field of computer vision and views it from a modern perspective. It is self-contained, accessible, and\n",
      "lays emphasis on basic geometry, physics of imaging and probabilistic techniques.\n",
      "\n",
      "Throughout, the authors attempt to lay bare the essentials of computer vision to the students as\n",
      "also to the professionals. The text reflects the latest developments in the field and integrates the\n",
      "learning tools that aid understanding.\n",
      "\n",
      " \n",
      "\n",
      "This uptodate, contemporary text would be useful for students of computer science, IT and MCA\n",
      "offering courses in computer graphics, robotics, image processing, and imaging in general. It would\n",
      "prove equally valuable for the professionals.\n",
      "\n",
      "KEY FEATURES\n",
      "\n",
      "Y Application Features—Numerous examples, including image based rendering and digital libraries\n",
      "Y Boxed Algorithms—Key algorithms broken out and illustrated in pseudo code\n",
      "W Extensive Detailed IMustrations—Examples of inputs and outputs for current methods\n",
      "\n",
      "Y Programming Assignments—50 programming assignments and 150 exercises\n",
      "\n",
      "= iui\n",
      "\n",
      "www.phindia.com\n"
     ]
    }
   ],
   "source": [
    "text3 = pytesseract.image_to_string('text3.jpg')\n",
    "print(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UQCMQ29_aF20"
   },
   "source": [
    "### <font color=\"green\">Observation </font>\n",
    "From the above output, you can see that Tesseract output even preserves the Capitalized words and the formatting, making it ideal for document analysis and OCR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Xhud4M4QV_V"
   },
   "source": [
    "# <font color=\"blue\">Output Type</font>\n",
    "Before going further, it is worth noting that the output of Tesseract is in the form of a **string by default**. There are other output types supported like a **dictionary, Byte or DataFrame**. In many cases, changing the output format might help if you need to perform further analysis of the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wF_ImjAXHGxJ"
   },
   "source": [
    "# <font color=\"blue\">Tesseract Functions </font>\n",
    "\n",
    "- **`get_tesseract_version`** - Returns the Tesseract version installed in the system.\n",
    "- **`image_to_string`** - Returns the result of a Tesseract OCR run on the image as a single string\n",
    "- **`image_to_boxes`** - Returns the recognized characters and their box boundaries.\n",
    "- **`image_to_data`** - Returns the box boundaries/locations, confidences, words etc. \n",
    "- **`image_to_osd`** - Returns result containing information about orientation and script detection.\n",
    "- **`image_to_pdf_or_hocr`** - Returns a searchable PDF from the input image.\n",
    "- **`run_and_get_output`** - Returns the raw output from Tesseract OCR. This gives a bit more control over the parameters that are sent to tesseract.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "686bQgCuPQpz"
   },
   "source": [
    "### <font color=\"green\">Check the detected characters </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "Y3MoQMgIRvFC",
    "outputId": "2b5d89a3-14bc-4cab-c3e5-e0ea7c0dee63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K 12 65 14 76 0\n",
      "e 14 65 21 76 0\n",
      "r 22 65 29 73 0\n",
      "a 31 65 35 73 0\n",
      "s 36 65 42 73 0\n",
      "i 43 65 49 73 0\n",
      "s 55\n"
     ]
    }
   ],
   "source": [
    "boxes = pytesseract.image_to_boxes(\"text1.jpg\")\n",
    "print(boxes[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sMAUENHtRz8N"
   },
   "source": [
    "You can see the result gives you the location of each recognized character. But, from the above, it is difficult to decipher how the location information is stored. Let us change the output type to dict which will show us what each of the column indicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "55i2acddPPRT",
    "outputId": "160a6537-a45d-4630-cb9c-1ba5f1bc32f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['char', 'left', 'bottom', 'right', 'top', 'page'])\n"
     ]
    }
   ],
   "source": [
    "boxes = pytesseract.image_to_boxes(\"text1.jpg\",output_type=\"dict\")\n",
    "print(boxes.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fU4wpVkoSQBE"
   },
   "source": [
    "So, the location is given by (left, bottom) and (top, right) coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q0yElQ3eSrHj"
   },
   "source": [
    "### <font color=\"green\">Check Detected Words </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "QKv5JxVUS3h-",
    "outputId": "ce74089a-c119-4693-969f-72fbf10839a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level\tpage_num\tblock_num\tpar_num\tline_num\tword_num\tleft\ttop\twidth\theight\tconf\ttext\n",
      "1\t1\t0\t0\t0\t0\t0\t0\t688\t91\t-1\t\n",
      "2\t1\t1\t0\t0\t0\t11\t14\t662\t63\t-1\t\n",
      "3\t1\t1\t1\t0\t0\t11\t14\t662\t63\t-1\t\n",
      "4\t1\t1\t1\t1\t0\t12\t14\t645\t15\t-1\t\n",
      "5\t1\t1\t1\t1\t1\t12\t15\t30\t11\t92\tKeras\n",
      "5\t1\t1\t1\t1\t2\t43\t15\t21\t11\t95\tis\n",
      "5\t1\t1\t1\t1\t3\t69\t18\t7\t8\t95\ta\n",
      "5\t1\t1\t1\t1\t4\t82\t14\t66\t15\t95\thigh-level\n",
      "5\t1\t1\t1\t1\t5\t154\t15\t42\t11\t96\tneural\n",
      "5\t1\t1\t1\t1\t6\t202\t15\t57\t11\t95\tnetworks\n",
      "5\t1\t1\t1\t1\t7\t260\t15\t34\t11\t95\tAPI,\n",
      "5\t1\t1\t1\t1\t8\t296\t15\t56\t13\t89\twritten\n",
      "5\t1\t1\t1\t1\t9\t358\t15\t11\t11\t96\tin\n",
      "5\t1\n"
     ]
    }
   ],
   "source": [
    "data = pytesseract.image_to_data(\"text1.jpg\")\n",
    "print(data[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CrwMtgL4PP-x",
    "outputId": "7ec4bb26-c91f-47eb-dab5-75e7855251b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['level', 'page_num', 'block_num', 'par_num', 'line_num', 'word_num', 'left', 'top', 'width', 'height', 'conf', 'text'])\n"
     ]
    }
   ],
   "source": [
    "data = pytesseract.image_to_data(\"text1.jpg\",output_type=\"dict\")\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bVrSToXwKFac"
   },
   "source": [
    "### <font color=\"green\">Create Searchable PDF from Image </font>\n",
    "It simply returns the raw tesseract output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1H-fxAf2-br2"
   },
   "outputs": [],
   "source": [
    "image2pdf = pytesseract.image_to_pdf_or_hocr('text2.jpg')\n",
    "with open('text2.pdf', 'w+b') as f:\n",
    "    f.write(image2pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZAGz_WtqKOTM"
   },
   "source": [
    "Now, download the PDF and check for yourself if the PDF is just a scanned image or it is searchable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bUlGN_dpKbsT"
   },
   "source": [
    "### <font color=\"green\">Check Orientation of the Text</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9G0w3oX0O9qo"
   },
   "outputs": [],
   "source": [
    "!wget https://wiki.openoffice.org/w/images/c/c2/WG3Ch7F14.png -O text3.png --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "haT6WP5QPBC6"
   },
   "source": [
    "### <font color=\"green\">Downloaded Image</font>\n",
    "![](https://wiki.openoffice.org/w/images/c/c2/WG3Ch7F14.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C5luVumj_to2"
   },
   "source": [
    "### <font color=\"green\">Output </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "C4pUun5w-bU4",
    "outputId": "58e22e44-53b7-4812-f698-4534173bec83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page number: 0\n",
      "Orientation in degrees: 270\n",
      "Rotate: 90\n",
      "Orientation confidence: 0.38\n",
      "Script: Latin\n",
      "Script confidence: 3.33\n"
     ]
    }
   ],
   "source": [
    "osd = pytesseract.image_to_osd(\"text3.png\")\n",
    "print(osd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HRN2jVhW_u65"
   },
   "source": [
    "You can see that the above document is rotated by 270 (or -90 ) degrees and it has been correctly detected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L85RvCXoLBZc"
   },
   "source": [
    "# <font color=\"blue\">What about a different language? </font>\n",
    "You can check out the list of supported languages [**here**](https://github.com/tesseract-ocr/tesseract/blob/master/doc/tesseract.1.asc#languages)\n",
    "We will see how to use Tesseract for German language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "S3d95htxMP7B",
    "outputId": "bc8b3e6a-0cc7-4f0f-ccde-abdfbcf20ed3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!apt install tesseract-ocr-deu > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4MYvIFDAcXJv"
   },
   "source": [
    "# <font color=\"blue\">Test Image 4 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bqudll7IK_fr"
   },
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/geevhmy62dy4pzh/german.jpg?dl=0 -O german.jpg --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M37ykE16LoUb"
   },
   "source": [
    "### Downloaded Image\n",
    "<img src=\"https://www.dropbox.com/s/geevhmy62dy4pzh/german.jpg?dl=1\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OQn4wYAqbWtL"
   },
   "source": [
    "### <font color=\"green\">Using Tesseract trained for English </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "JSKtYr0iK_sH",
    "outputId": "5690be8f-200e-4071-cde6-779023bf474a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English - detected ~ rod German ~\n",
      "\n",
      "Can we check x K6nnen wir\n",
      "\n",
      "whether Uberpriifen, ob\n",
      "Tesseract Tesseract Deutsch\n",
      "understand versteht?\n",
      "\n",
      "German?\n"
     ]
    }
   ],
   "source": [
    "text4 = pytesseract.image_to_string('german.jpg',lang='eng')\n",
    "print(text4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JHpySRV1bXYp"
   },
   "source": [
    "### <font color=\"green\">Using Tesseract trained for German </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "F2avpowuK_zG",
    "outputId": "6e39d88a-f398-4cf6-93df-7e485e3fcd5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English - detected = eo German =\n",
      "\n",
      "Can we check x Können wir\n",
      "\n",
      "whether überprüfen, ob\n",
      "Tesseract Tesseract Deutsch\n",
      "understand versteht?\n",
      "\n",
      "German?\n"
     ]
    }
   ],
   "source": [
    "text4_german = pytesseract.image_to_string('german.jpg',lang='deu')\n",
    "print(text4_german)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-JItaMh_Qa-3"
   },
   "source": [
    "### <font color=\"green\">Observation </font>\n",
    "You can see that even though it is able to detect most words correctly, but the german language details are missing. For example, \n",
    "1. **`überprüfen`** is detected as **`Uberpriifen`**\n",
    "1. **`Können`** is detected as **`K6nnen`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tr1VvgbCivHb"
   },
   "source": [
    "# <font color=\"blue\">Tesseract OCR on Natural Scene Images</font>\n",
    "We have seen how Tesseract performs on scanned documents. The challenging part is how to handle natural scene images because they can have any type of variations ranging from low quality/lighting issues/occlusion/distortion etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bXkUcWEHj78L"
   },
   "source": [
    "# <font color=\"blue\">Test Image 5</font>\n",
    "We will use an image taken from the camera of the same scan that we used earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8rO0V9Q2itp4"
   },
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/jat0z82d76zlkjg/book1.jpg?dl=1 -O book1.jpg --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gze9Akgnjv5V"
   },
   "source": [
    "### Downloaded Image\n",
    "<img src=\"https://www.dropbox.com/s/jat0z82d76zlkjg/book1.jpg?dl=1\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "colab_type": "code",
    "id": "p8HGhLDDit1I",
    "outputId": "0f3354ff-e879-4135-e036-48a55d8086a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computer Vision\n",
      "A MODERN APPROACH\n",
      "\n",
      "DAVID A. FORSYTH\n",
      "\n",
      "University of California at Berkeley\n",
      "\n",
      "JEAN PONCE\n",
      "\n",
      "University of Illinois at Urbana-Champaign\n",
      "\n",
      "Whether in the entertainment industry (building three-dimensiona! computer models), medical imaging,\n",
      "interpreting satellite images (both for military and civilian purposes), the applications of computer\n",
      "vision is varied and wide ranging. And this compact yet comprehensive text provides a survey of the\n",
      "field of computer vision and views it from a modern perspective. It is self-contained, accessible, and\n",
      "lays emphasis on basic geometry, physics of imaging and probabilistic techniques.\n",
      "\n",
      "Throughout, the authors attempt to lay bare the essentials of computer vision to the students as\n",
      "also to the professionals. The text reflects the latest developments in the field and integrates the\n",
      "learning tools that aid understanding.\n",
      "\n",
      "This uptodate, contemporary text would be useful for students of computer science, IT and MCA\n",
      "offering courses in computer graphics, robotics, image processing, and imaging in general. It would\n",
      "prove equally valuable for the professionals.\n",
      "\n",
      "KEY FEATURES\n",
      "\n",
      "Y Application Features—Numerous examples, including image based rendering and digital libraries\n",
      "Y Boxed Algorithms—Key algorithms broken out and illustrated in pseudo code\n",
      "Y Extensive Detailed Iilustrations—Examples of inputs and outputs for current methods\n",
      "\n",
      "Y Programming Assignments—50 programming assignments and 150 exercises\n",
      "\n",
      "am Wn\n",
      "\n",
      "phindla\n",
      "\n",
      "Bhutan, india, Maldives, Nepal, Pakistan and Sri Lanka Cs\n"
     ]
    }
   ],
   "source": [
    "text5 = pytesseract.image_to_string('book1.jpg')\n",
    "print(text5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mLKqKc-1Zoay"
   },
   "source": [
    "### <font color=\"green\">Observation</font>\n",
    "Even though it is natural image, Tesseract is able to perform OCR almost without any errors. This is good, but you will be surprised by how fast the output deteriorates on small changes in the images. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XAOXdTpZvOEW"
   },
   "source": [
    "# <font color=\"blue\">Test Image 6</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m5YjoL6qvOWh"
   },
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/uwrdek4jjac4ysz/book2.jpg?dl=1 -O book2.jpg --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6kCyyYfWvllI"
   },
   "source": [
    "### Downloaded Image\n",
    "\n",
    "<img src=\"https://www.dropbox.com/s/uwrdek4jjac4ysz/book2.jpg?dl=1\" width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-r8x0wZYwgws",
    "outputId": "d07457b3-a132-47f0-fa25-2bdf7c745bae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Impact of the Highly Improbable\n"
     ]
    }
   ],
   "source": [
    "text6 = pytesseract.image_to_string('book2.jpg')\n",
    "print(text6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bgFJkHHsZPVp"
   },
   "source": [
    "### <font color=\"green\">Observation </font>\n",
    "So, it was only able to detect the above text. This needs to be fixed or at least improved. We will see that in the next section."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "1_Text_Recognition_Tesseract.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
